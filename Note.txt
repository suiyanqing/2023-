RNN循环神经网络：前面序列经过简单处理，作为输入信息传入后部序列

RNN处理自然语言:
词汇数值化：建立一个词汇--数值  一一对应的字典，然后把输入词汇转化为数值矩阵
	更细致化分：将字母和数值一一对应-----字典更小，对模型要求更高


RNN结构：
	i个输入对应i个输出，多输入对应多输出，维度相同的RNN结构
	应用：特定信息的识别


	多输入对应单输出
	应用：情感识别
		Eg.I feel happy watching the movie.
		判断:positive

	单输入对应多输出
	应用：序列数据生成器
		Eg,文章生成，音乐生成


	i个输入对应j个输出（i！=j）
	应用：语言翻译


普通RNN的缺陷：
	通过a[i]传递前面的序列信息，距离越远信息系丢失的越多---a[i]前面序列的基本信息


LSTM单元：
	增加记忆细胞c[i],可以传递前面远处部位信息---前面序列的重要信息，减少传递过程中信息的丢失

数据处理过程：
	忘记门：选择丢弃a[i]与x[i]中不重要的信息
	更新门：确定给记忆细胞添加哪些信息
	输出门：筛选需要输出的信息

卷积运算：
	将卷积核在遍历时，对应位置相乘再相加，和填入二维矩阵的对应位置

	索伯滤波器--边缘检测器--找出局部图像特征-边缘


池化：图像中的相邻像素倾向于具有相似的值，因此通常卷积层相邻的输出像素也有相似的值，这意味着，卷积层输出包含的大部分信息都是冗余的

池化层通过减少输入的大小降低输出的数量---一般通过简单的取最大值、最小值或平均值来操作完成

卷积神经网络：输入层--卷积层--池化层--全连接层--输出层
